{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by\n",
    "# https://github.com/fjg00/Facebook-Group-Post-Scraper/blob/main/Facebook%20Group%20Parser.py\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER DEFINED INPUTS\n",
    "import Login\n",
    "CHROME_DRIVER_PATH = './chromedriver' # must download this yourself\n",
    "\n",
    "# EMAIL, PASSWORD from Login file \n",
    "EMAIL = Login.EMAIL\n",
    "PASSWORD = Login.PASSWORD\n",
    "\n",
    "# Group number\n",
    "GROUP_ID = 1379345962387168 #USER INPUT\n",
    "GROUP_URL = 'https://www.facebook.com/groups/'+str(GROUP_ID)\n",
    "\n",
    "SEARCH_PROMPT = \"\" # something to be searched for in the group\n",
    "SEARCH_PROMPT = SEARCH_PROMPT.replace(\" \",\"%20\")\n",
    "\n",
    "# Copy the group description and put it here to be able to filter it out\n",
    "GROUP_DESCRIPTION = \"\"\"-Kamer in Eindhoven-\n",
    "Kamer in Eindhoven is een platform waar vraag en aanbod (kosteloos) worden samengebracht. Ben je opzoek naar een kamer, huisgenoot of bied je een kamer aan, word dan nu lid van deze facebookgroep.\n",
    "Je scrollt door de nieuwste kamers en huisgenoten om vervolgens direct te reageren naar de aanbieder. Bij ons geen inschrijfkosten, gewoon studenten onder elkaar.\n",
    "Kamer in Eindhoven is onderdeel van de Facebook community Zoekt Kamer inâ€¦ Wij zijn ook actief in Nijmegen, Amsterdam, Delft, Rotterdam, Groningen, Maastricht, Breda, Utrecht, Leiden, Den Haag, Haarlem en Amersfoort.\n",
    "Sinds 2020 hebben wij een samenwerking met de gratis app MyHospi. Hiermee willen wij het proces voor jullie nog makkelijker maken.\n",
    "HOE WERKT MYHOSPI VOOR HUIZEN?\n",
    "1. Plaats de kamer op myHospi via de app.\n",
    "2. Deel de link naar het huis in je FB bericht en geef aan dat mensen via myHospi (de link) moeten reageren. Met myHospi krijg je direct een compleet beeld van de mensen die reageren op jouw kamer. Geen onpersoonlijke mails maar complete profielen.\n",
    "3. Swipe en Like!\n",
    "4. Nodig kandidaten uit en deel de link naar je videocall.\"\"\" # User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addvalues(dictionary: dict, key, L: list):\n",
    "    \"\"\"Append multiple values to a key in the given dictionary\"\"\"\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = list()\n",
    "    dictionary[key].extend(L)\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41316/3073893559.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(CHROME_DRIVER_PATH, options=chrome_options) #USER INPUT\n"
     ]
    }
   ],
   "source": [
    "# Webdriver options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--disable-notifications')\n",
    "chrome_options.add_argument('headless')\n",
    "\n",
    "driver = webdriver.Chrome(CHROME_DRIVER_PATH, options=chrome_options) #USER INPUT\n",
    "driver.get('https://www.facebook.com/')\n",
    "\n",
    "WebDriverWait(driver, 20).until(EC.element_to_be_clickable((By.XPATH, \"//button[@class='_42ft _4jy0 _9xo6 _4jy3 _4jy1 selected _51sy']\"))).click()\n",
    "email = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"input[name = 'email']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"input[name = 'pass']\")))\n",
    "\n",
    "\n",
    "email.clear()\n",
    "password.clear()\n",
    "\n",
    "email.send_keys(EMAIL) #USER INPUT\n",
    "password.send_keys(PASSWORD) #USER INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open window, select group\n",
    "login = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"button[type = 'submit']\"))).click()\n",
    "\n",
    "#maximize window\n",
    "driver.maximize_window()\n",
    "\n",
    "n_scrolls = 2\n",
    "\n",
    "# Gets FB group with search parameters\n",
    "driver.get(GROUP_URL+SEARCH_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection criteria\n",
    "text = \"\"\n",
    "comments = \"\"\n",
    "z = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scroll through the page and get all links\n",
    "def extract(comment):\n",
    "    return comment.partition('?comment')[0]\n",
    "\n",
    "def getPostURLs(limit: int):\n",
    "    \"\"\" Get a list of post URLs from the Facebook group of choice.\n",
    "\n",
    "    Args: \n",
    "        limit (int): number of post URLs that should be returned.\n",
    "\n",
    "    Returns:\n",
    "        posts (list): list of post URLs.\n",
    "    \"\"\"\n",
    "\n",
    "    all_urls = []\n",
    "    posts_number = 0\n",
    "    posts = []\n",
    "\n",
    "    while len(posts) <= limit:\n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        a_tags = driver.find_elements(By.TAG_NAME, 'a')\n",
    "        new_urls = [a.get_attribute('href') for a in a_tags]\n",
    "\n",
    "        # New URLs should be of post or comment type (which is a subtype of a post URL). \n",
    "        new_comments = [a for a in new_urls if (str(a).startswith(GROUP_URL+'/posts/'))]\n",
    "\n",
    "        # Only extract the post URL, not interested in the comment links.\n",
    "        new_posts = set(extract(comment) for comment in new_comments if extract(comment) not in posts)\n",
    "        posts.extend(list(new_posts))\n",
    "\n",
    "        # Print progress\n",
    "        if len(posts) < limit:\n",
    "            print ('collected', len(posts))\n",
    "        else:\n",
    "            print ('collected:', limit)\n",
    "    \n",
    "    return posts[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected 1\n",
      "collected 4\n",
      "collected: 5\n"
     ]
    }
   ],
   "source": [
    "posts = getPostURLs(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grab post and comment data\n",
    "# # TODO make nice df out of it\n",
    "# # TODO grab info about posters and commenters\n",
    "# # TODO grab time data (and time difference between post and comment)\n",
    "\n",
    "\n",
    "# WrapperDict = list() \n",
    "# texts = []\n",
    "# translatedBools = []\n",
    "# commentCounts = []\n",
    "\n",
    "# for postCount, a in enumerate(posts):\n",
    "#         driver.get(a)\n",
    "#         time.sleep(1)\n",
    "        \n",
    "#         page_source = driver.page_source\n",
    "#         soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "#         # Relevant classes for text (or translate button)\n",
    "#         translateBtnText = \"x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1o1ewxj x3x9cwd x1e5q0jg x13rtm0m x1n2onr6 x87ps6o x1a2a7pz xt0b8zv\"\n",
    "#         translateBtn = soup.find('div', class_ = translateBtnText)\n",
    "#         translatedTextClass = \"x193iq5w xeuugli x13faqbe x1vvkbs x10flsy6 x6prxxf xvq8zen xo1l8bm xzsf02u x1yc453h\"\n",
    "#         originalTextClass = \"x193iq5w xeuugli x13faqbe x1vvkbs x10flsy6 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x4zkp8e x41vudc x6prxxf xvq8zen xo1l8bm xzsf02u x1yc453h\"\n",
    "\n",
    "#         if (translateBtn is not None) and (soup.find('div', class_ = translateBtnText).text == \"See Translation\"):\n",
    "#                 isTranslated = False\n",
    "#                 # Original\n",
    "#                 # text = soup.find('span' , class_ = originalTextClass).text #post\n",
    "#                 t = soup.find('div', class_ = \"x1swvt13 x1l90r2v x1pi30zi x1iorvi4\")\n",
    "#                 if t is not None:\n",
    "#                         text = t.text #post\n",
    "#                 else:\n",
    "#                         # This may result in text=\"Facebook\", could find all of this class and choose one where it doesn't equal Facebook\n",
    "#                         text = soup.find('span' , class_ = originalTextClass).text #post\n",
    "#         elif soup.find('span', class_ = translatedTextClass) is not None:\n",
    "#                 # Translated\n",
    "#                 text = soup.find('span' , class_ = translatedTextClass).text #post\n",
    "#                 isTranslated = True\n",
    "#         elif soup.find('span', class_ = originalTextClass) is not None:\n",
    "#                 # Original English\n",
    "#                 text = soup.find('span', class_ = originalTextClass).text #post\n",
    "#                 isTranslated = False\n",
    "\n",
    "#         # isTranslated = len(soup.find_all('span', class_ = \"x193iq5w xeuugli x13faqbe x1vvkbs x10flsy6 x1pg5gke xvq8zen xo1l8bm x1qq9wsj x1yc453h\")) > 0\n",
    "#         # TODO instead of length check that it equals expected text ('See original' or 'Rate this translation')\n",
    "\n",
    "#         commentCount = soup.find('span', class_ = \"x193iq5w xeuugli x13faqbe x1vvkbs x10flsy6 x1lliihq x1s928wv xhkezso x1gmr53x x1cpjm7i x1fgarty x1943h6x x4zkp8e x41vudc x6prxxf xvq8zen xo1l8bm xi81zsa\").text\n",
    "#         commentCount = int(re.search(r'\\d+', commentCount).group())\n",
    "        \n",
    "#         # TODO create DF/dictionary/smth with all this info\n",
    "#         texts.append(text)\n",
    "#         translatedBools.append(isTranslated)\n",
    "#         commentCounts.append(commentCount)\n",
    "#         if postCount % 5 == 0:\n",
    "#                 print (postCount)\n",
    "\n",
    "#         # w = 1\n",
    "        \n",
    "#         # BranchDict = dict()\n",
    "#         # BranchDict[\"tag\"] = 1\n",
    "#         # BranchDict[\"patterns\"] = 1\n",
    "#         # BranchDict[\"responses\"] = list()\n",
    "#         # L = list()\n",
    "        \n",
    "#         # for post in actualPosts:\n",
    "#         #     s = post.get_text()\n",
    "#         #     # if (s == \"INSERT GROUP DESCRIPTION HERE\"): #USER INPUT\n",
    "#         #     if (s == GROUP_DESCRIPTION): #USER INPUT\n",
    "#         #         time.sleep(1)\n",
    "#         #     elif len(s.split()) < 4:\n",
    "#         #         time.sleep(1)\n",
    "#         #     else:\n",
    "#         #         if w == 1: #post\n",
    "#         #             text= text + post.get_text() \n",
    "#         #             BranchDict[\"tag\"] = SEARCH_PROMPT + str(z) \n",
    "#         #             BranchDict[\"patterns\"] = text\n",
    "#         #             w = w + text1\n",
    "#         #         elif w > 1 : #comments\n",
    "#         #             comments = post.get_text()\n",
    "#         #             L.append(comments)\n",
    "#         #             comments = \"\"\n",
    "#         # z = z + 1\n",
    "#         # addvalues(BranchDict, \"responses\", L)\n",
    "#         # WrapperDict.append(BranchDict)\n",
    "#         # text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the headless session (to avoid it staying alive in memory)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df = pd.DataFrame([texts, translatedBools, commentCounts], columns=['Text', 'Is_Translated', 'Comment_Count'])\n",
    "# df = pd.DataFrame.from_dict({\"Text\": texts, \"Is_Translated\": translatedBools, \"Comment_Count\": commentCounts, 'URL': list(posts)})\n",
    "\n",
    "# # # Flatten text if necessary\n",
    "# # def flatten(text):\n",
    "# #     if text is list:\n",
    "# #         text = ''.join(text)\n",
    "# #         print (text)\n",
    "# #     return text\n",
    "# # df['Text'] = df['Text'].apply(flatten)\n",
    "# # df.iloc[0]['URL']\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it, brother\n",
    "# df.to_csv(path_or_buf='scraped_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69eddf76122a7a77fa761679cc76164f49f300d238d45f30943e7d02df2c26d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
