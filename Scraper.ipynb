{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by\n",
    "# https://github.com/fjg00/Facebook-Group-Post-Scraper/blob/main/Facebook%20Group%20Parser.py\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USER DEFINED INPUTS\n",
    "import Login\n",
    "CHROME_DRIVER_PATH = './chromedriver' # must download this yourself\n",
    "\n",
    "# EMAIL, PASSWORD from Login file (explained in README.md)\n",
    "EMAIL = Login.EMAIL\n",
    "PASSWORD = Login.PASSWORD\n",
    "\n",
    "# Group number\n",
    "GROUP_IDS = [1379345962387168, \"kamer.in.eindhoven\"] #USER INPUT\n",
    "GROUP_URLS = []\n",
    "for id in GROUP_IDS:\n",
    "    item = 'https://www.facebook.com/groups/'+str(id)\n",
    "    GROUP_URLS.append(item)\n",
    "\n",
    "SEARCH_PROMPT = \"\" # something to be searched for in the group\n",
    "SEARCH_PROMPT = SEARCH_PROMPT.replace(\" \",\"%20\")\n",
    "\n",
    "# TODO populate this\n",
    "# Copy the group description and put it here to be able to filter it out\n",
    "GROUP_DESCRIPTIONS = [\"\"\"-Kamer in Eindhoven-\n",
    "Kamer in Eindhoven is een platform waar vraag escraper.posts[0]n aanbod (kosteloos) worden samengebracht. Ben je opzoek naar een kamer, huisgenoot of bied je een kamer aan, word dan nu lid van deze facebookgroep.\n",
    "Je scrollt door de nieuwste kamers en huisgenoten om vervolgens direct te reageren naar de aanbieder. Bij ons geen inschrijfkosten, gewoon studenten onder elkaar.\n",
    "Kamer in Eindhoven is onderdeel van de Facebook community Zoekt Kamer inâ€¦ Wij zijn ook actief in Nijmegen, Amsterdam, Delft, Rotterdam, Groningen, Maastricht, Breda, Utrecht, Leiden, Den Haag, Haarlem en Amersfoort.\n",
    "Sinds 2020 hebben wij een samenwerking met de gratis app MyHospi. Hiermee willen wij het proces voor jullie nog makkelijker maken.\n",
    "HOE WERKT MYHOSPI VOOR HUIZEN?\n",
    "1. Plaats de kamer op myHospi via de app.\n",
    "2. Deel de link naar het huis in je FB bericht en geef aan dat mensen via myHospi (de link) moeten reageren. Met myHospi krijg je direct een compleet beeld van de mensen die reageren op jouw kamer. Geen onpersoonlijke mails maar complete profielen.\n",
    "3. Swipe en Like!\n",
    "4. Nodig kandidaten uit en deel de link naar je videocall.\"\"\"] # User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FBScraper import FBScraper\n",
    "scraper = FBScraper(CHROME_DRIVER_PATH, Login.EMAIL, Login.PASSWORD)\n",
    "scraper.openAndLogin(hide=True)\n",
    "scraper.setGroupInfo(GROUP_IDS)\n",
    "scraper.getAllInfo(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# Save\n",
    "scraper.all_info.to_csv(f'{now}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.closeSession()\n",
    "# print(scraper.all_info.iloc[0][\"Post\"])\n",
    "# print(scraper.all_info.iloc[0][\"Poster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def addvalues(dictionary: dict, key, L: list):\n",
    "#     \"\"\"Append multiple values to a key in the given dictionary\"\"\"\n",
    "#     if key not in dictionary:\n",
    "#         dictionary[key] = list()\n",
    "#     dictionary[key].extend(L)\n",
    "#     return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens FB group with search parameters\n",
    "# driver.get(GROUP_URL+SEARCH_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getPosterURL(post: str, group_id: int, page_source=None, soup=None):\n",
    "#     driver.get(post)\n",
    "#     time.sleep(1)\n",
    "#     # TODO something here is broken. Fix this.\n",
    "#     poster_class = \"x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz xt0b8zv xzsf02u x1s688f\"\n",
    "\n",
    "#     link = driver.page_source if page_source is None else page_source\n",
    "#     page_source = 'https://www.facebook.com' + page_source if link is None else link\n",
    "\n",
    "\n",
    "#     soup = BeautifulSoup(page_source, 'html.parser') if soup is None else soup\n",
    "\n",
    "#     urls = soup.find_all('a', class_=poster_class)\n",
    "#     urls = [url['href'] for url in urls]\n",
    "\n",
    "#     identifier = \"/groups/\" + str(group_id)\n",
    "#     try:\n",
    "#         url = [url for url in urls if identifier in url][0]\n",
    "#     except:\n",
    "#         url = [url for url in urls if identifier in url]    \n",
    "#     url = \"https://www.facebook.com\" + str(url)\n",
    "\n",
    "#     return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getPosterList(post_list: list, group_url: str):\n",
    "#     urls = []\n",
    "#     for count, post in enumerate(post_list):\n",
    "#         urls.append(getPosterURL(post, group_url))\n",
    "#         if count % 10:\n",
    "#             print (count, ' posters gotten')\n",
    "#     return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getLastXPosters(X: int, group_url):\n",
    "#     tolerance_diff = 5\n",
    "#     posts = getPostURLs(X+tolerance_diff, group_url)\n",
    "    \n",
    "#     now = datetime.now()\n",
    "#     now = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
    "    \n",
    "#     # Save before continuing\n",
    "#     pdf = pd.DataFrame({'post': posts})\n",
    "#     pdf.to_csv(f'{now}_{X}_posts.csv', index=False)\n",
    "\n",
    "#     posters = getPosterList(posts, group_url)\n",
    "    \n",
    "#     pdf = pd.DataFrame({'profiles': posters})\n",
    "#     pdf.to_csv(f'{now}_{X}_profiles.csv', index=False)\n",
    "\n",
    "#     return posters, posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posters, posts = getLastXPosters(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO move this to the FBScraper class\n",
    "# def message(profile: str, msg: str):\n",
    "#     # Add enter to message so that it gets sent\n",
    "#     msg_end = msg[len(msg)-2] + msg[len(msg)-1]\n",
    "#     if msg_end != \"\\n\":\n",
    "#         msg = msg + \"\\n\"\n",
    "\n",
    "#     # Open the profile\n",
    "#     driver.get(profile)\n",
    "    \n",
    "#     # Click the \"Message\" button\n",
    "#     xpath_msg_btn = \"//span[contains(text(),'Message')]\"\n",
    "#     page_source = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath_msg_btn))).click()\n",
    "\n",
    "#     # Write something in the input\n",
    "#     xpath_input = \"//p[@class='xdj266r xat24cr']\"\n",
    "#     input_field = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, xpath_input)))\n",
    "#     input_field.send_keys(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it, brother\n",
    "# df.to_csv(path_or_buf='scraped_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "69eddf76122a7a77fa761679cc76164f49f300d238d45f30943e7d02df2c26d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
